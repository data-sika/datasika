name: airbnb-baby-proj
schedule:
  # every month's first day
  - cron: "0 0 1 * *"

pipeline:
  stages:
    - id: airbnb-stage
      description: "stages for airbnb data"
      tasks:
        # id: <verb>
        # user_input:
        #   fields:
        #     - name: <what you will get back after the syntax> <noun>
        - id: webscrap_airbnb
          description: "get airbnb website page url"
          type: read
          function: http-request
          inputs:
            user_input:
              file_name: 'input.csv'
              file_format: csv
              # value: 'http://insideairbnb.com/get-the-data.html' (inside the csv file)
        - id: extract_table_content
          description: "get table content by xpath syntax"
          type: filter
          function: xpath
          inputs:
            user_input:
              field: '//table[@class="table table-hover table-striped tokyo"]//tr'
            task_inputs:
              - from: webscrap_airbnb
        - id: extract_row_content
          description: "get row content by column names & xpath syntax"
          type: filter
          function: xpath
          # use for loop to do things for each element(row)
          inputs:
            user_input:
              fields:
                - name: time
                  value: './/td[1]/text()'
                - name: description
                  value: './/td[4]/text()'
                - name: file_link
                  value: './/td[3]//a/@href'
            task_inputs:
              - from: extract_table_content
        - id: filter_date
          description: "get date-filtered data by sql syntax"
          type: filter
          function: sql
          inputs:
            user_input:
              field: "
                    SELECT `time`, `description`, `file_link`
                    FROM extract_row_content 
                    WHERE time = '28 December, 2021'
                  "
            task_inputs:
              - from: extract_row_content
        - id: get_listing_file_link
          description: "get file link by sql syntax"
          type: filter
          function: sql
          inputs:
            user_input:
              field: "
                    SELECT `file_link`
                    FROM filter_date
                    WHERE description
                    LIKE '%listings data%'
                  "
            task_inputs:
              - from: filter_date
        - id: request_listing_file
          description: "request file link"
          type: read
          function: http-request
          inputs:
            task_inputs:
              - extract_field: file_link
                from: get_listing_file_link
        # HOOK
        - id: decompress_file_str
          description: "decompress file str"
          type: transform
          function: decompress
          inputs:
            task_inputs:
              - from: request_listing_file
        - id: read_csv_str_to_table
          description: "read csv str to dataframe"
          type: transform
          function: transform-to-dataframe
          inputs:
            task_inputs:
              - str_type: csv
                from: decompress_file_str
        - id: filter_transform_listing
          description: "filter & transform fields by sql syntax"
          type: filter
          function: sql
          inputs:
            user_input:
              field: "
                    SELECT
                        `id`, `listing_url`, `name`, `latitude`, `longitude`, `price`, `number_of_reviews`, 
                        `review_scores_rating`, `review_scores_accuracy`, `review_scores_cleanliness`, 
                        `review_scores_checkin`, `review_scores_communication`, `review_scores_location`,
                        `review_scores_value`,  (30-availability_30) as unavailability_30, 1 as key
                    FROM read_csv_str_to_table
                    WHERE has_availability = 't' 
                       AND ((90-availability_90) != 90 OR (365-availability_365) != 365)
                    "
            task_inputs:
              - from: read_csv_str_to_table
    - name: covid19-stage
      tasks:
        - id: reques_covid_api
          description: "get covid api url"
          type: read
          function: http-request
          inputs:
            # this use different user input type then the first task of webscrapping task 
            user_input:
              file_name: 'input2.csv'
              file_format: csv
              # value: "https://covid19-japan-web-api.vercel.app/api/v1/total?history=true"
        # HOOK
        - id: transform_json_to_dataframe
          description: "turn json to dataframe"
          type: transform
          function: transform-to-dataframe
          inputs:
            task_inputs:
              - str_type: json
                from: request_covid_api
        - id: calculate_covid_cases
          description: "calculate positive cases & deaths by sql, also add a key for outer join"
          type: filter
          function: sql
          inputs:
            user_input:
              field: "
                    SELECT  (max(positive) - min(positive)) as positive, (max(death) - min(death)) as death, 1 as key
                    FROM request_covid_api
                    WHERE date = '20211128' OR date = '20211228'
                  "
            task_inputs:
              - from: transform_json_to_dataframe
    - name: merged-stage
      tasks:
        - id: combine_airbnb_covid_data
          name: "combined two data sources into a big dataframe"
          type: merge
          function: sql
          inputs:
            user_input:
              field: "
                    SELECT
                      `id`, `listing_url`, `name`, `latitude`, `longitude`, `price`, `number_of_reviews`, 
                      `review_scores_rating`, `review_scores_accuracy`, `review_scores_cleanliness`, 
                      `review_scores_checkin`, `review_scores_communication`, `review_scores_location`, `review_scores_value`,
                      jp_covid30_df.positive as jp_covid30_cases,  jp_covid30_df.death as jp_covid30_deaths, `unavailability_30`
                    FROM airbnb_df
                    LEFT OUTER JOIN  jp_covid30_df
                      ON airbnb_df.key = jp_covid30_df.key
                  "
            task_inputs:
              - type: dataframe
                from: filter-transform-listing
                description: "airbnb dataframe"
              - type: dataframe
                from: calculate-covid-cases
                description: "jp covid19 dataframe"
          outputs:
            - type: dataframe
              name: covid_added_df
              description: "airbnb + covid19 dataframe merged"
        - id: transform-price
          name: "transform price"
          type: transform
          function: sql
          inputs:
            user_input:
              type: dataframe
              fields:
                - name: price_transformed
                  value: "
                    SELECT `unavailability_30`, `latitude`, `longitude`,
                      CAST(REPLACE(REPLACE(REPLACE(price, '$', ''), '.00', ''), ',' ,'') AS INT) as price,
                      `number_of_reviews`, `review_scores_rating`, `review_scores_accuracy`, `review_scores_cleanliness`, 
                      `review_scores_checkin`, `review_scores_communication`, `review_scores_location`,
                      `review_scores_value`, `jp_covid30_cases`, `jp_covid30_deaths`
                    FROM covid_added_df
                  "
            task_inputs:
              - type: dataframe
                from: combine-airbnb-covid-data
          outputs:
            - type: dataframe
              name: price_transformed_df
              description: "price transformed dataframe"
        - id: filter-nan-rows
          name: "filter NaN rows"
          type: filter
          function: sql
          inputs:
            user_input:
              type: dataframe
              fields:
                - name: delete 
                  value: true
                - name: null_filtered
                  value: "
                    DELETE FROM price_transformed_df
                    WHERE `unavailability_30` IS NULL OR `latitude` IS NULL OR `longitude` IS NULL OR
                      `number_of_reviews` IS NULL OR `review_scores_rating` IS NULL OR `review_scores_accuracy` IS NULL OR 
                      `review_scores_cleanliness` IS NULL OR `review_scores_checkin` IS NULL OR `review_scores_communication` IS NULL OR 
                      `review_scores_location` IS NULL OR `review_scores_value` IS NULL OR  `jp_covid30_cases` IS NULL OR `jp_covid30_deaths` IS NULL OR
                      `price` IS NULL;
                  "
            task_inputs:
              - type: dataframe
                from: transform-price
          outputs:
            - type: dataframe
              name: final_df
              description: "final output"
          last_task: true






          




